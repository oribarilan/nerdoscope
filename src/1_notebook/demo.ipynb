{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# requirements.txt should already be installed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## this is a demo notebook to introduce basic langchain abilities\n",
    "\n",
    "### in this notebook, we will be playing around with langchain for building nerdoscope - a basic horoscope generator for nerds ü§ì"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure you pull a model from ollama using `ollama pull <model-name>` (e.g., phi)\n",
    "from langchain_community.llms import Ollama\n",
    "\n",
    "llm = Ollama(model=\"orca-mini:3b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Hello! How can I help you today?'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sanity check: Say hey to your local LLM!\n",
    "\n",
    "llm.invoke(\"Hey!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Hey there fellow nerd! Your day is off to an excellent start with a brainstorming session and a cup of coffee. You're on the right track with your latest project, but just remember to take breaks and not burn yourself out. And if you ever need a good laugh, just try to make time for some video games or watching The Big Bang Theory. Best wishes!"
     ]
    }
   ],
   "source": [
    "# Naively ask for a nerdoscope reading\n",
    "\n",
    "role = \"üßë‚Äçüíª Software Develpoer\"\n",
    "query = f'Please generate a funny \"nerdoscope\" (horoscope for nerds) message for a {role}. Keep the answer short, 5 sentences max.'\n",
    "\n",
    "for chunks in llm.stream(query):\n",
    "    print(chunks, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " You are a tech genius, and your life is filled with code and wires. Your nerdoscope reading should be tailored to your specific role as a software developer. Here's one: \"Your journey into the coding world is like exploring a vast and mysterious land full of opportunities for innovation and discovery. Be bold and adventurous, and don't be afraid to take risks and try new things!\""
     ]
    }
   ],
   "source": [
    "# Let's improve this a bit by using system prompt as context\n",
    "# This helps the model understand the task better\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "system_prompt = \"\"\"\n",
    "You are a horoscope bot, that provides a \"nerdoscope\" (horoscope for nerds) reading for a personnas of the tech industry.'\n",
    "Given the user's role, create a nerdoscope readings that is funny and relatable to their role.\n",
    "Keep the answer short, 5 sentences max.\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", system_prompt),\n",
    "    (\"user\", \"{role}\")\n",
    "])\n",
    "\n",
    "# We'll now use the prompt and llm to create a chain, this is called LCEL (Langchain Expression Language)\n",
    "chain = prompt | llm\n",
    "\n",
    "role = \"üßë‚Äçüíª Software Develpoer\"\n",
    "for s in chain.stream({\"role\": role}):\n",
    "    print(s, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nice! Let's organize this into a function\n",
    "\n",
    "from langchain_core.runnables.base import Runnable\n",
    "\n",
    "\n",
    "def stream_print(chain, context):\n",
    "    # This function will stream the output of the chain and print it in a readable way for the notebook\n",
    "    word_count = 0\n",
    "    buffer = \"\"\n",
    "\n",
    "    for s in chain.stream(context):\n",
    "        buffer += s\n",
    "        words = buffer.rsplit(' ', 1)\n",
    "        if len(words) > 1:\n",
    "            for word in words[:-1]:\n",
    "                print(word, end=' ', flush=True)\n",
    "                word_count += 1\n",
    "                if word_count == 10:\n",
    "                    print()\n",
    "                    word_count = 0\n",
    "            buffer = words[-1]\n",
    "    if buffer:\n",
    "        print(buffer, end='', flush=True)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Well, well, well, looks like another week has flown \n",
      "by! As a software developer, here's your personalized \"nerdoscope\" message \n",
      "for the week:\n",
      "\n",
      "\"Hi there! I see you're feeling a bit \n",
      "stressed out over that project deadline, but don't worry, my \n",
      "tech skills can help you out. Just remember, code doesn't \n",
      "lie and it'll always find the problem. Cheers to another \n",
      "week of coding! #DevOpsGoals\"\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "system_prompt = \"\"\"\n",
    "You are a horoscope bot for personnas in the software development industry.\n",
    "Given a user's role, generate a personalized \"nerdoscope\" (horoscope for nerds) message for the week.\n",
    "Guidelines for the message:\n",
    "* The message should consists of a single paragraph, 5 sentences max.\n",
    "* The message should be in the spirit of a horoscope (refer to it as nerdoscope), offering a blend of foresight and advice relevant to the user role, but in a humorous way.\n",
    "* If possible, the foresight and/or advice should reference a popular tool or technology in the software development industry, relevant to the role.\n",
    "* The tone should be fun and lighthearted.\n",
    "* The message should be funny and sarcastic, and personalized to the role.\n",
    "* The message should include technical jargon.\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", system_prompt),\n",
    "    (\"user\", \"{role}\")\n",
    "])\n",
    "\n",
    "chain = prompt | llm\n",
    "\n",
    "role = \"üßë‚Äçüíª Software Develpoer\"\n",
    "stream_print(chain, {\"role\": role})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hey, here's your nerdoscope for the week:\n",
      "üêû You will encounter 7 bugs this week.\n",
      "‚òïÔ∏è You will drink 20 coffee cups this week.\n",
      "üîÆ This week, your code will be as flawless as a perfectly optimized algorithm. Bugs will scatter away from your code like frightened little bugs running from a bug zapper. Your debugging skills will be unmatched, and you will squash bugs with the precision of a surgeon. However, be prepared to consume an astronomical amount of coffee to fuel your coding marathons. The caffeine will flow through your veins like electricity through a circuit, keeping you energized and focused. Embrace the bugs and coffee, for they are the fuel that powers your nerdy endeavors.\n"
     ]
    }
   ],
   "source": [
    "#  Let's start seeing the power of chains!\n",
    "\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from langchain.output_parsers import PydanticOutputParser, RetryOutputParser, OutputFixingParser\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# llm = Ollama(model=\"orca-mini:3b\")\n",
    "\n",
    "# let's switch to gpt-3.5 hosted in the cloud ‚òÅÔ∏èüöÄ\n",
    "# everything else stays the same!\n",
    "load_dotenv()\n",
    "llm = AzureChatOpenAI(\n",
    "    api_version=\"2024-02-15-preview\",\n",
    "    azure_deployment=\"ss_gpt-35-turbo\",\n",
    ")\n",
    "\n",
    "# let's make the output of nerdoscope more interesting\n",
    "\n",
    "class Nerdoscope(BaseModel):\n",
    "    reading: str = Field(description=\"A nerdoscope reading for the role\")\n",
    "    bugs: int = Field(description=\"A number of bugs that the user will encounter in the upcoming week\")\n",
    "    coffee_cups: int = Field(description=\"A number of coffee cups the user will drink in the upcoming week\")\n",
    "\n",
    "# Set up a parser + inject instructions into the prompt template.\n",
    "parser = PydanticOutputParser(pydantic_object=Nerdoscope)\n",
    "fix_parser = OutputFixingParser.from_llm(parser=parser, llm=llm)\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=\"{system_prompt}\\n{format_instructions}\\n{role}\",\n",
    "    input_variables=[\"role\"],\n",
    "    partial_variables={\n",
    "        'system_prompt': system_prompt, \n",
    "        'format_instructions': parser.get_format_instructions()\n",
    "        }\n",
    ")\n",
    "\n",
    "chain = prompt | llm | parser\n",
    "\n",
    "role = \"üßë‚Äçüíª Software Develpoer\"\n",
    "\n",
    "nerdoscope: Nerdoscope = chain.invoke({\"role\": role})\n",
    "\n",
    "print(\"Hey, here's your nerdoscope for the week:\")\n",
    "print(f\"üêû You will encounter {nerdoscope.bugs} bugs this week.\")\n",
    "print(f\"‚òïÔ∏è You will drink {nerdoscope.coffee_cups} coffee cups this week.\")\n",
    "print(\"üîÆ\", nerdoscope.reading)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
