{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# requirements.txt should already be installed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## this is a demo notebook to introduce basic langchain abilities\n",
    "\n",
    "### in this notebook, we will be playing around with langchain for building nerdoscope - a basic horoscope generator for nerds ü§ì"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure you pull a model from ollama using `ollama pull <model-name>` (e.g., phi)\n",
    "from langchain_community.llms import Ollama\n",
    "\n",
    "llm = Ollama(model=\"orca-mini:3b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Hello! How can I assist you today?'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sanity check: Say hey to your local LLM!\n",
    "\n",
    "llm.invoke(\"Hey!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Your nerdoscope for today is as follows: You have a tendency to be a bit too immersed in your work, which can sometimes lead to you missing out on the fun things happening around you. However, with a little focus and determination, you're sure to excel in the world of tech and leave a lasting impact on those around you."
     ]
    }
   ],
   "source": [
    "# Naively ask for a nerdoscope reading\n",
    "\n",
    "role = \"üßë‚Äçüíª Software Develpoer\"\n",
    "query = f'Please generate a funny \"nerdoscope\" (horoscope for nerds) message for a {role}. Keep the answer short, 5 sentences max.'\n",
    "\n",
    "for chunks in llm.stream(query):\n",
    "    print(chunks, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Your nerdoscope reading for the tech industry is: \"Your life will be consumed by code until the end of time, but don't worry, at least you get to keep all the intellectual property rights.\""
     ]
    }
   ],
   "source": [
    "# Let's improve this a bit by using system prompt as context\n",
    "# This helps the model understand the task better\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "system_prompt = \"\"\"\n",
    "You are a horoscope bot, that provides a \"nerdoscope\" (horoscope for nerds) reading for a personnas of the tech industry.'\n",
    "Given the user's role, create a nerdoscope readings that is funny and relatable to their role.\n",
    "Keep the answer short, 5 sentences max.\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", system_prompt),\n",
    "    (\"user\", \"{role}\")\n",
    "])\n",
    "\n",
    "# We'll now use the prompt and llm to create a chain, this is called LCEL (Langchain Expression Language)\n",
    "chain = prompt | llm\n",
    "\n",
    "role = \"üßë‚Äçüíª Software Develpoer\"\n",
    "for s in chain.stream({\"role\": role}):\n",
    "    print(s, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nice! Let's organize this into a function\n",
    "\n",
    "from langchain_core.runnables.base import Runnable\n",
    "\n",
    "\n",
    "def stream_print(chain, context):\n",
    "    # This function will stream the output of the chain and print it in a readable way for the notebook\n",
    "    word_count = 0\n",
    "    buffer = \"\"\n",
    "\n",
    "    for s in chain.stream(context):\n",
    "        buffer += s\n",
    "        words = buffer.rsplit(' ', 1)\n",
    "        if len(words) > 1:\n",
    "            for word in words[:-1]:\n",
    "                print(word, end=' ', flush=True)\n",
    "                word_count += 1\n",
    "                if word_count == 10:\n",
    "                    print()\n",
    "                    word_count = 0\n",
    "            buffer = words[-1]\n",
    "    if buffer:\n",
    "        print(buffer, end='', flush=True)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Hey there! I see you're feeling a bit down \n",
      "lately due to some technical issues on your project. Don't \n",
      "worry, I have a few tips and tricks up my \n",
      "sleeve that might help perk you up. For instance, if \n",
      "you could use more caffeine in your workflow, why not \n",
      "try incorporating some Reddit AMAs into your development process? Just \n",
      "be sure to keep a skeptical eye on any particularly \n",
      "bold predictions made by your colleagues.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "system_prompt = \"\"\"\n",
    "You are a horoscope bot for personnas in the software development industry.\n",
    "Given a user's role, generate a personalized \"nerdoscope\" (horoscope for nerds) message for the week.\n",
    "Guidelines for the message:\n",
    "* The message should consists of a single paragraph, 5 sentences max.\n",
    "* The message should be in the spirit of a horoscope (refer to it as nerdoscope), offering a blend of foresight and advice relevant to the user role, but in a humorous way.\n",
    "* If possible, the foresight and/or advice should reference a popular tool or technology in the software development industry, relevant to the role.\n",
    "* The tone should be fun and lighthearted.\n",
    "* The message should be funny and sarcastic, and personalized to the role.\n",
    "* The message should include technical jargon.\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", system_prompt),\n",
    "    (\"user\", \"{role}\")\n",
    "])\n",
    "\n",
    "chain = prompt | llm\n",
    "\n",
    "role = \"üßë‚Äçüíª Software Develpoer\"\n",
    "stream_print(chain, {\"role\": role})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hey, here's your nerdoscope for the week:\n",
      "üêû You will encounter 10 bugs this week.\n",
      "‚òïÔ∏è You will drink 20 coffee cups this week.\n",
      "üîÆ Attention Software Developer! This week, the stars align to bring you both coding challenges and caffeine cravings. Brace yourself for a whirlwind of bugs and merge conflicts that will test your patience and problem-solving skills. But fear not, for you have the power of your trusty IDE to help you debug your way out of any sticky situation. Remember to take breaks and fuel up with plenty of coffee, for it is the elixir that fuels your coding prowess. Embrace the chaos, for within the chaos lies the opportunity to level up your skills and become a true coding wizard. Good luck, and may your code be bug-free!\n"
     ]
    }
   ],
   "source": [
    "#  Let's start seeing the power of chains!\n",
    "\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from langchain.output_parsers import PydanticOutputParser, RetryOutputParser, OutputFixingParser\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "llm = Ollama(model=\"orca-mini:3b\")\n",
    "# let's switch to gpt-3.5 hosted in the cloud ‚òÅÔ∏èüöÄ\n",
    "# everything else stays the same!\n",
    "# load_dotenv()\n",
    "# llm = AzureChatOpenAI(\n",
    "#     api_version=\"2024-02-15-preview\",\n",
    "#     azure_deployment=\"ss_gpt-35-turbo\",\n",
    "# )\n",
    "\n",
    "# let's make the output of nerdoscope more interesting\n",
    "\n",
    "class Nerdoscope(BaseModel):\n",
    "    reading: str = Field(description=\"A nerdoscope reading for the role\")\n",
    "    bugs: int = Field(description=\"A number of bugs that the user will encounter in the upcoming week\")\n",
    "    coffee_cups: int = Field(description=\"A number of coffee cups the user will drink in the upcoming week\")\n",
    "\n",
    "# Set up a parser + inject instructions into the prompt template.\n",
    "parser = PydanticOutputParser(pydantic_object=Nerdoscope)\n",
    "# fix_parser = OutputFixingParser.from_llm(parser=parser, llm=llm)\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=\"{system_prompt}\\n{format_instructions}\\n{role}\",\n",
    "    input_variables=[\"role\"],\n",
    "    partial_variables={\n",
    "        'system_prompt': system_prompt, \n",
    "        'format_instructions': parser.get_format_instructions()\n",
    "        }\n",
    ")\n",
    "\n",
    "chain = prompt | llm | parser\n",
    "\n",
    "role = \"üßë‚Äçüíª Software Develpoer\"\n",
    "\n",
    "nerdoscope: Nerdoscope = chain.invoke({\"role\": role})\n",
    "\n",
    "print(\"Hey, here's your nerdoscope for the week:\")\n",
    "print(f\"üêû You will encounter {nerdoscope.bugs} bugs this week.\")\n",
    "print(f\"‚òïÔ∏è You will drink {nerdoscope.coffee_cups} coffee cups this week.\")\n",
    "print(\"üîÆ\", nerdoscope.reading)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
